{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzliBOFcQgqMXBoN4LTg/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ling-lyanna-zhang/reserve-neural-policy/blob/main/try_gurobi_reserve_39bus_(step1)benchmarks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q3UWPo6mISo",
        "outputId": "d2f0e3c8-9407-43d3-9636-2377c0eb3447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in case gpu is used\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QCAsDEcmR1O",
        "outputId": "811f3b61-0fe2-424d-e3e5-b48f00f7e162"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "import cvxpy as cp\n",
        "import random\n",
        "from numpy import savetxt\n",
        "import argparse\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "root_path = './gdrive/MyDrive/Inbox/rs_neural_policy/'\n"
      ],
      "metadata": {
        "id": "mvxphpwn1Th-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.init.trunc_normal__(tensor: Tensor, \n",
        "#                        mean: float = 0., \n",
        "#                        std: float = 1., \n",
        "#                        a: float = -2., \n",
        "#                        b: float = 2.)"
      ],
      "metadata": {
        "id": "b26P-dMF7L_Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MOSEK if not already installed\n",
        "!pip install mosek"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FVaBLdMSBy5",
        "outputId": "1a3ce7d1-6ff2-4fbe-b410-2f5bfb9ceb92"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mosek in /usr/local/lib/python3.7/dist-packages (10.0.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cp.installed_solvers())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buOB3KjHS609",
        "outputId": "3ee92e0c-79d5-418d-9622-d4996d5a0160"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CVXOPT', 'ECOS', 'ECOS_BB', 'GLPK', 'GLPK_MI', 'GUROBI', 'MOSEK', 'OSQP', 'SCIPY', 'SCS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# helper functions, can be folded"
      ],
      "metadata": {
        "id": "7AfB0oo7mnIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utils.py"
      ],
      "metadata": {
        "id": "JRt8IRhLmx8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(PATH):\n",
        "    isExist = os.path.exists(PATH)\n",
        "\n",
        "    if not isExist:\n",
        "        # Create a new directory if it does not exist \n",
        "        os.makedirs(PATH)\n",
        "        print(\"The new directory is created!\")\n",
        "\n",
        "\n",
        "# Evaluate using vector distance\n",
        "def measure_relative_distance(v1, v2):\n",
        "    '''\n",
        "        Note that v1 is the benchmark.\n",
        "        Norm is calculated along dimension/axis 1\n",
        "        and average is calculated along dimension/axis 0\n",
        "        Also return the distance vetor.\n",
        "    '''\n",
        "    if len(v1.shape)==1 and len(v2.shape)==1:\n",
        "        distance = np.abs(v1-v2)/np.abs(v1)\n",
        "\n",
        "    if len(v1.shape)==2 and len(v2.shape)==2:\n",
        "        distance = np.linalg.norm(v1-v2, axis=1)/np.linalg.norm(v1, axis=1)\n",
        "\n",
        "    return distance, np.mean(distance)"
      ],
      "metadata": {
        "id": "R4SwyMaKmmou"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## paths.py"
      ],
      "metadata": {
        "id": "6r89GhdeKzox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paths():\n",
        "    params_path = root_path+'39bus/params/'\n",
        "    data_path = root_path+'39bus/data/'\n",
        "    model_path = root_path+'39bus/saved_models/'\n",
        "    saved_path = root_path+'39bus/predictions/'\n",
        "\n",
        "\n",
        "    isExist = os.path.exists(data_path)\n",
        "    if not isExist:\n",
        "        # Create a new directory if it does not exist \n",
        "        os.makedirs(data_path)\n",
        "\n",
        "    isExist = os.path.exists(model_path)\n",
        "    if not isExist:\n",
        "        # Create a new directory if it does not exist \n",
        "        os.makedirs(model_path)\n",
        "\n",
        "    \n",
        "    isExist = os.path.exists(saved_path)\n",
        "    if not isExist:\n",
        "        # Create a new directory if it does not exist \n",
        "        os.makedirs(saved_path)\n",
        "\n",
        "    return params_path, data_path, saved_path, model_path"
      ],
      "metadata": {
        "id": "0OYFwYxJK2cU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cost_coeff(params_path):    \n",
        "    quad_cost_coeff = np.load(params_path+'quad_cost_coeff.npy')\n",
        "    linear_cost_coeff = np.load(params_path+'linear_cost_coeff.npy')\n",
        "    da_cost_coeff = np.load(params_path+'da_cost_coeff.npy')\n",
        "\n",
        "    return quad_cost_coeff, linear_cost_coeff, da_cost_coeff\n"
      ],
      "metadata": {
        "id": "LOgocLNQMquO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## system.py"
      ],
      "metadata": {
        "id": "YCN03qDPnEpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_unique_lines(connections):\n",
        "    all_lines = {}\n",
        "    count = 0\n",
        "    for line in connections:\n",
        "        all_lines[count] = line\n",
        "        count+=1\n",
        "\n",
        "    # This code snippet only finds out the repeated lines with exactly the same order of nodes,\n",
        "    # but not deal with that [i,j] and [j,i] are also repeated lines\n",
        "    # By checking connections, there is no repeated lines like [i,j] and [j,i]\n",
        "    unique_lines = {}\n",
        "    for k, val in all_lines.items():\n",
        "        if val not in unique_lines.values():\n",
        "            unique_lines[k]=val\n",
        "    print('unique_lines length:', len(unique_lines))\n",
        "\n",
        "    repeated_lines = [[42, 49],[49, 54],[56, 59],[49, 66],[77, 80],[89, 90],[89, 92]]\n",
        "    # For example, [42, 49] appears twice\n",
        "    set1 = {}\n",
        "    set2 = {}\n",
        "    for k, val in all_lines.items():\n",
        "        if val in repeated_lines and k in unique_lines:\n",
        "            set1[val[0], val[1]] = k # Record the repeated lines when they first appear\n",
        "        if val in repeated_lines and k not in unique_lines:\n",
        "            set2[val[0], val[1]] = k # Record the repeated lines when they appear more than once\n",
        "\n",
        "    # print('set1:', len(set1))\n",
        "    # print('set2:', len(set2))\n",
        "\n",
        "    return unique_lines, set1, set2\n",
        "\n",
        "\n",
        "def get_Y(N, B):\n",
        "    # N = num_buses\n",
        "    Y = np.zeros((N, N))\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            if i==j : \n",
        "                Y[i,j] = sum(B[i,:])\n",
        "            else: \n",
        "                Y[i,j] = -B[i,j]\n",
        "\n",
        "    return Y[:,1:]\n",
        "\n",
        "\n",
        "def get_A(N, L, B, connections):\n",
        "    # N = num_buses\n",
        "    # L = num_lines \n",
        "    A = np.zeros((L, N))\n",
        "\n",
        "    for i, line in enumerate(connections):\n",
        "        row = line[0]-1\n",
        "        col = line[1]-1\n",
        "        A[i, row] = B[row,col]\n",
        "        A[i, col] = -B[row,col]\n",
        "\n",
        "    return A[:,1:]\n",
        "\n",
        "\n",
        "# Import 39bus\n",
        "def import_39bus(params_path):\n",
        "    bus_data_fname = '39bus_BusData.csv'\n",
        "    gen_data_fname = '39bus_GenData.csv'\n",
        "    branch_data_fname = '39bus_BranchData.csv'\n",
        "    cost_data_fname = '39bus_CostData.csv'\n",
        "\n",
        "    bus_data_df = pd.read_csv(params_path+bus_data_fname,header=None)\n",
        "    gen_data_df = pd.read_csv(params_path+gen_data_fname,header=None)\n",
        "    branch_data_df = pd.read_csv(params_path+branch_data_fname,header=None)\n",
        "    cost_data_df = pd.read_csv(params_path+cost_data_fname,header=None)\n",
        "\n",
        "\n",
        "    num_buses = bus_data_df.shape[0]\n",
        "    num_lines = branch_data_df.shape[0]\n",
        "    num_gens = gen_data_df.shape[0]\n",
        "\n",
        "\n",
        "    bus_data = bus_data_df.to_numpy()\n",
        "    gen_data = gen_data_df.to_numpy()\n",
        "    branch_data = branch_data_df.to_numpy()\n",
        "    cost_data = cost_data_df.to_numpy()\n",
        "\n",
        "    x = branch_data[:,3]\n",
        "    print('max of x:', max(x))\n",
        "    print('min of x:', min(x))\n",
        "\n",
        "\n",
        "    b = 1/x\n",
        "    Z0 = 10\n",
        "    b = b/Z0\n",
        "    print('max of b:', max(b))\n",
        "    print('min of b:', min(b))\n",
        "\n",
        "    connections = []\n",
        "    branches = branch_data[:,:2]\n",
        "    for i in range(branches.shape[0]):\n",
        "            connections.append([int(branches[i,0]),int(branches[i,1])])\n",
        "    print('len of connections:', len(connections))\n",
        "\n",
        "    unique_lines, set1, set2 = identify_unique_lines(connections)\n",
        "\n",
        "    B = np.zeros((num_buses, num_buses))\n",
        "    for k, line in unique_lines.items():\n",
        "        row = line[0]-1\n",
        "        col = line[1]-1\n",
        "        B[row, col] = b[k]\n",
        "        B[col, row] = b[k]\n",
        "\n",
        "    PD = bus_data[:,2]/20\n",
        "    print('Total PD:', sum(PD))\n",
        "\n",
        "    return num_buses, num_lines, B, connections, PD"
      ],
      "metadata": {
        "id": "BikI-OcI51au"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import B, F and cost"
      ],
      "metadata": {
        "id": "KGa5hT7oK7yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_path, data_path, saved_path, model_path = get_paths()\n",
        "\n",
        "num_buses, num_lines, B, connections, PD_data = import_39bus(params_path)\n",
        "\n",
        "N = num_buses\n",
        "L = num_lines \n",
        "\n",
        "Yrr = get_Y(num_buses, B)\n",
        "Arr = get_A(num_buses, num_lines, B, connections)\n",
        "\n",
        "# # Define feasibility set for gauge mapping\n",
        "# G = np.block([\n",
        "#               [Arr],\n",
        "#               [-Arr],\n",
        "#               [np.eye(N-1)],\n",
        "#               [-np.eye(N-1)]\n",
        "# ])\n",
        "# print('G shape:', G.shape)\n",
        "\n",
        "# Load cost coefficients\n",
        "quad_cost_coeff, linear_cost_coeff, da_cost_coeff = load_cost_coeff(params_path) \n",
        "\n",
        "quad_cost_Coeff = np.diag(quad_cost_coeff)\n",
        "linear_cost_Coeff = linear_cost_coeff.reshape(-1, 1)\n",
        "da_cost_Coeff = da_cost_coeff.reshape(-1,1)\n",
        "\n",
        "print('quad_cost_Coeff shape:', quad_cost_Coeff.shape)\n",
        "print('linear_cost_Coeff shape:', linear_cost_Coeff.shape)\n",
        "print('da_cost_Coeff shape:', da_cost_Coeff.shape)\n",
        "\n",
        "c = da_cost_Coeff\n",
        "q = linear_cost_Coeff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bda42JdMK8PC",
        "outputId": "dde98d84-9644-473d-84f8-c7a8db769523"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max of x: 0.062\n",
            "min of x: 0.003\n",
            "max of b: 33.33333333333333\n",
            "min of b: 1.6129032258064515\n",
            "len of connections: 46\n",
            "unique_lines length: 46\n",
            "Total PD: 156.35575\n",
            "quad_cost_Coeff shape: (39, 39)\n",
            "linear_cost_Coeff shape: (39, 1)\n",
            "da_cost_Coeff shape: (39, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### set Pmax/Pmin, Fmax and std"
      ],
      "metadata": {
        "id": "xeXa0ytiLAPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DayAheadReserveCostFactor = 1.1\n",
        "RecourseReserveCostFactor = 5.\n",
        "Pmax = 30.\n",
        "Pmin = 0.\n",
        "Fmax = 15.\n",
        "\n",
        "input_std = 0.1\n",
        "sce_std = 0.05"
      ],
      "metadata": {
        "id": "xLKTLTCLLAok"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataloader.py"
      ],
      "metadata": {
        "id": "_XaV-g1PnHWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def for_sinlge_instance(forecast, x):\n",
        "\n",
        "    p0 = x[:N,:]\n",
        "    r_up = x[N:N+N,:]\n",
        "    r_down = x[N+N:,:]\n",
        "\n",
        "    theta = cp.Variable((N-1,1))\n",
        "    y = cp.Variable((N, 1))\n",
        "\n",
        "    constraints_list = []\n",
        "\n",
        "    PD = forecast.flatten()\n",
        "    std_vec = PD*sce_std\n",
        "    std_vec = np.where(std_vec<1e-5, 0.1, std_vec)\n",
        "\n",
        "    rt_scenario = np.random.multivariate_normal(PD, np.diag(std_vec), 1)\n",
        "    # generated scenario are arranged in rows, must be transposed\n",
        "    rt_scenario = np.clip(rt_scenario, a_min=0., a_max=None).T\n",
        "    assert rt_scenario.shape[0] == N\n",
        "    \n",
        "    net_d_omega = rt_scenario - p0\n",
        "\n",
        "    constraints_list.append( y == Yrr@theta + net_d_omega )\n",
        "\n",
        "    constraints_list.append( p0 + y <= Pmax*np.ones((N, 1)))\n",
        "    constraints_list.append( p0 + y >= Pmin*np.ones((N, 1)))\n",
        "    # constraints_list.append( y <= r_up)\n",
        "    # constraints_list.append( y >= -r_down)\n",
        "        \n",
        "    constraints_list.append( Arr@theta <= Fmax*np.ones((num_lines, 1)))\n",
        "    constraints_list.append( Arr@theta >= -Fmax*np.ones((num_lines, 1)))\n",
        "\n",
        "    constraints_list.append( theta<=np.pi)\n",
        "    constraints_list.append( theta>=-np.pi)\n",
        "\n",
        "    recourse_cost = cp.abs(y).T@q +\\\n",
        "        cp.pos(y-r_up).T@q*RecourseReserveCostFactor +\\\n",
        "        cp.pos(y+r_down).T@q*RecourseReserveCostFactor\n",
        "\n",
        "    Q_pred = recourse_cost\n",
        "\n",
        "    prob = cp.Problem(cp.Minimize( Q_pred ), constraints_list)\n",
        "\n",
        "    prob.solve(verbose = False, solver = cp.ECOS) ## Works!   \n",
        "\n",
        "    return prob.value, y.value, theta.value, net_d_omega, prob.status"
      ],
      "metadata": {
        "id": "-HCTIrhW7qN3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_stochastic_dcopf(forecasts, x_vals):\n",
        "    '''\n",
        "    Given a single instance and the initial dispatch x, and evaluate the quality\n",
        "    of x.\n",
        "    This function can be applied to the decision obtained from any policy.\n",
        "    '''\n",
        "    num_points = forecasts.shape[0]\n",
        "\n",
        "    Q_vals = []\n",
        "    y_vals = []\n",
        "    theta_vals = []\n",
        "    net_d_vals = []\n",
        "    for i in range(num_points):\n",
        "        forecast = forecasts[i,:].reshape(-1,1)\n",
        "        x = x_vals[i,:].reshape(-1,1)\n",
        "\n",
        "        Q_omega, y_omega, theta_omega, net_d_omega, prob_status = for_sinlge_instance(forecast, x)\n",
        "\n",
        "        if prob_status in [\"infeasible\", \"unbounded\"]:\n",
        "            print(\"Problem is \" + str(prob_status))\n",
        "            Q_omega = 0.\n",
        "            y_omega = np.zeros((N, 1))\n",
        "            theta_omega = np.zeros((N-1, 1))\n",
        "\n",
        "        Q_vals.append(Q_omega)\n",
        "        y_vals.append(y_omega.flatten())\n",
        "        theta_vals.append(theta_omega.flatten())\n",
        "        net_d_vals.append(net_d_omega.flatten())\n",
        "\n",
        "    Q_vals = np.array(Q_vals).reshape(-1,1)\n",
        "    y_vals = np.array(y_vals)\n",
        "    theta_vals = np.array(theta_vals)\n",
        "    net_d_vals = np.array(net_d_vals)\n",
        "\n",
        "    return Q_vals, y_vals, theta_vals, net_d_vals\n"
      ],
      "metadata": {
        "id": "eMTE7hboL-6k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## benchmarks.py"
      ],
      "metadata": {
        "id": "FjLzC7u1nQS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### solver"
      ],
      "metadata": {
        "id": "2dSQ9gjN20Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_GAP(forecast, num_sce):\n",
        "    '''\n",
        "    Implemented by following the GAP model in [Kannan, Luedtke, Roald(2020)].\n",
        "    I think it is kind of weird that y doesn't have an offset and the second-stage\n",
        "    is totally determined by the uncertainties.\n",
        "    So implement modified GAP instead.\n",
        "    '''\n",
        "\n",
        "    M = num_sce\n",
        "\n",
        "    # c = da_cost_Coeff\n",
        "    # q = linear_cost_Coeff\n",
        "    B = -Yrr\n",
        "    F = Arr\n",
        "    rho_lb = 10.\n",
        "    rho_ub = 10.\n",
        "    gamma_lb = 10.\n",
        "    gamma_ub = 10.\n",
        "    ones = np.ones((N,1))\n",
        "\n",
        "    Brr = -Yrr[1:,:]\n",
        "    Brr_inv = np.linalg.inv(Brr)\n",
        "    I = np.eye(N)\n",
        "    R = I[1:,:]\n",
        "    \n",
        "    # first-stage decision variables\n",
        "    x = cp.Variable((N, 1))\n",
        "    r_up = cp.Variable((N, 1))\n",
        "    r_down = cp.Variable((N, 1))\n",
        "    alpha = cp.Variable((N, 1))\n",
        "\n",
        "    # no second-stage decision variables\n",
        "    # beta = cp.Variable((N,1))\n",
        "\n",
        "    # theta = cp.Variable((N-1,M))\n",
        "\n",
        "    constraints_list = []\n",
        "\n",
        "    Q_vals = []\n",
        "\n",
        "    # generate M uncertainty realizations\n",
        "    PD = forecast.flatten()\n",
        "    std_vec = PD*sce_std\n",
        "    std_vec = np.where(std_vec<1e-5, 0.1, std_vec)\n",
        "\n",
        "    scenarios = np.random.multivariate_normal(PD, np.diag(std_vec), M)\n",
        "    scenarios = np.clip(scenarios, a_min=0., a_max=None).T\n",
        "    assert scenarios.shape[0] == N\n",
        "\n",
        "    for m in range(M):\n",
        "        # for each scenario of noise\n",
        "        omega =  scenarios[:, m:m+1] - forecast\n",
        "        net_d = scenarios[:, m:m+1] - x\n",
        "\n",
        "        # y_pred = (ones.T@omega)*alpha + beta\n",
        "        y_pred = (ones.T@omega)*alpha\n",
        "        theta_pred = Brr_inv@R@(net_d-y_pred)\n",
        "\n",
        "        constraints_list.append( y_pred == Yrr@theta_pred + net_d )\n",
        "\n",
        "        p_f_lb = rho_lb*cp.square( cp.norm( cp.pos(-Fmax*np.ones((num_lines, 1)) - F@theta_pred) ) )\n",
        "        p_f_ub = rho_ub*cp.square( cp.norm(  cp.pos(F@theta_pred -Fmax*np.ones((num_lines, 1))) ) )\n",
        "\n",
        "        p_theta_lb  = rho_lb*cp.square( cp.norm(  cp.pos(-np.pi*np.ones((N-1, 1)) - theta_pred) ) )\n",
        "        p_theta_ub  = rho_ub*cp.square( cp.norm(  cp.pos(theta_pred - np.pi*np.ones((N-1, 1))) ) )\n",
        "\n",
        "        p_y_ub  = gamma_lb*cp.square( cp.norm( cp.pos(x+y_pred-Pmax*np.ones((N, 1))) ))\n",
        "        p_y_lb  = gamma_ub*cp.square( cp.norm( cp.pos(Pmin*np.ones((N, 1))-(x+y_pred) ) ))\n",
        "\n",
        "        recourse_cost = cp.abs(y_pred).T@q +\\\n",
        "                cp.pos(y_pred-r_up).T@q*RecourseReserveCostFactor +\\\n",
        "                cp.pos(y_pred+r_down).T@q*RecourseReserveCostFactor\n",
        "\n",
        "        Q_val = recourse_cost + p_f_lb + p_f_ub + p_theta_lb + p_theta_ub\n",
        "        Q_val += p_y_ub + p_y_lb\n",
        "\n",
        "        Q_vals.append(Q_val)\n",
        "\n",
        "    constraints_list.append( ones.T@x== ones.T@forecast)\n",
        "    constraints_list.append( x+r_up <= Pmax*np.ones((N, 1)))\n",
        "    constraints_list.append( x-r_down >= Pmin*np.ones((N, 1)))\n",
        "    constraints_list.append( x>=Pmin)\n",
        "    constraints_list.append( x<=Pmax)\n",
        "    constraints_list.append( r_up>=0)\n",
        "    constraints_list.append( r_down>=0)\n",
        "    constraints_list.append( ones.T@alpha==1)\n",
        "    constraints_list.append( alpha>=0)\n",
        "\n",
        "    Q_pred = cp.sum(Q_vals)/M\n",
        "\n",
        "    da_cost = c.T@x + DayAheadReserveCostFactor*c.T@(r_up+r_down)\n",
        "\n",
        "    prob = cp.Problem(cp.Minimize( da_cost + Q_pred ), constraints_list)\n",
        "\n",
        "    prob.solve(verbose = False, solver = cp.ECOS) ## Works!  \n",
        "\n",
        "    solutions = np.concatenate([x.value.T, r_up.value.T, r_down.value.T], axis=-1)\n",
        "\n",
        "\n",
        "    return solutions, prob.value, prob.status"
      ],
      "metadata": {
        "id": "csyX9d53XFYK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_modified_GAP(forecast, num_sce):\n",
        "    '''\n",
        "    Implemented by following the GAP model in [Kannan, Luedtke, Roald(2020)].\n",
        "    I think it is kind of weird that y doesn't have an offset and the second-stage\n",
        "    is totally determined by the uncertainties.\n",
        "    So implement modified GAP instead.\n",
        "    '''\n",
        "\n",
        "    M = num_sce\n",
        "\n",
        "    # c = da_cost_Coeff\n",
        "    # q = linear_cost_Coeff\n",
        "    B = -Yrr\n",
        "    F = Arr\n",
        "    rho_lb = 10.\n",
        "    rho_ub = 10.\n",
        "    gamma_lb = 10.\n",
        "    gamma_ub = 10.\n",
        "    ones = np.ones((N,1))\n",
        "\n",
        "    Brr = -Yrr[1:,:]\n",
        "    Brr_inv = np.linalg.inv(Brr)\n",
        "    I = np.eye(N)\n",
        "    R = I[1:,:]\n",
        "    \n",
        "    # first-stage decision variables\n",
        "    x = cp.Variable((N, 1))\n",
        "    r_up = cp.Variable((N, 1))\n",
        "    r_down = cp.Variable((N, 1))\n",
        "    alpha = cp.Variable((N, 1))\n",
        "\n",
        "    # second-stage decision variables\n",
        "    beta = cp.Variable((N,1))\n",
        "\n",
        "\n",
        "    constraints_list = []\n",
        "    Q_vals = []\n",
        "\n",
        "    PD = forecast.flatten()\n",
        "    std_vec = PD*sce_std\n",
        "    std_vec = np.where(std_vec<1e-5, 0.1, std_vec)\n",
        "\n",
        "    # generate M uncertainty realizations using the given forecast as mean\n",
        "    # vector and 5% of it as std.\n",
        "    scenarios = np.random.multivariate_normal(PD, np.diag(std_vec), M)\n",
        "    scenarios = np.clip(scenarios, a_min=0., a_max=None).T\n",
        "    assert scenarios.shape[0] == N\n",
        "\n",
        "    for m in range(M):\n",
        "        # for each scenario of noise\n",
        "        omega =  scenarios[:, m:m+1] - forecast\n",
        "        net_d = scenarios[:, m:m+1] - x\n",
        "\n",
        "        y_pred = (ones.T@omega)*alpha + beta\n",
        "        theta_pred = Brr_inv@R@(net_d-y_pred)\n",
        "\n",
        "        constraints_list.append( y_pred == Yrr@theta_pred + net_d )\n",
        "\n",
        "        p_f_lb = rho_lb*cp.square( cp.norm( cp.pos(-Fmax*np.ones((num_lines, 1)) - F@theta_pred) ) )\n",
        "        p_f_ub = rho_ub*cp.square( cp.norm(  cp.pos(F@theta_pred -Fmax*np.ones((num_lines, 1))) ) )\n",
        "\n",
        "        p_theta_lb  = rho_lb*cp.square( cp.norm(  cp.pos(-np.pi*np.ones((N-1, 1)) - theta_pred) ) )\n",
        "        p_theta_ub  = rho_ub*cp.square( cp.norm(  cp.pos(theta_pred - np.pi*np.ones((N-1, 1))) ) )\n",
        "\n",
        "        p_y_ub  = gamma_lb*cp.square( cp.norm( cp.pos(x+y_pred-Pmax*np.ones((N, 1))) ))\n",
        "        p_y_lb  = gamma_ub*cp.square( cp.norm( cp.pos(Pmin*np.ones((N, 1))-(x+y_pred) ) ))\n",
        "\n",
        "        recourse_cost = cp.abs(y_pred).T@q +\\\n",
        "                cp.pos(y_pred-r_up).T@q*RecourseReserveCostFactor +\\\n",
        "                cp.pos(y_pred+r_down).T@q*RecourseReserveCostFactor\n",
        "\n",
        "        Q_val = recourse_cost + p_f_lb + p_f_ub + p_theta_lb + p_theta_ub\n",
        "        Q_val += p_y_ub + p_y_lb\n",
        "\n",
        "        Q_vals.append(Q_val)\n",
        "\n",
        "    constraints_list.append( ones.T@x== ones.T@forecast)\n",
        "    constraints_list.append( x+r_up <= Pmax*np.ones((N, 1)))\n",
        "    constraints_list.append( x-r_down >= Pmin*np.ones((N, 1)))\n",
        "    constraints_list.append( x>=Pmin)\n",
        "    constraints_list.append( x<=Pmax)\n",
        "    constraints_list.append( r_up>=0)\n",
        "    constraints_list.append( r_down>=0)\n",
        "    constraints_list.append( ones.T@alpha==1)\n",
        "    constraints_list.append( alpha>=0)\n",
        "\n",
        "    Q_pred = cp.sum(Q_vals)/M\n",
        "\n",
        "    da_cost = c.T@x + DayAheadReserveCostFactor*c.T@(r_up+r_down)\n",
        "\n",
        "    prob = cp.Problem(cp.Minimize( da_cost + Q_pred ), constraints_list)\n",
        "\n",
        "    prob.solve(verbose = False, solver = cp.ECOS) ## Works!  \n",
        "\n",
        "    solutions = np.concatenate([x.value.T, r_up.value.T, r_down.value.T], axis=-1)\n",
        "\n",
        "\n",
        "    return solutions, prob.value, prob.status"
      ],
      "metadata": {
        "id": "5IR3qz5krglL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_AP(forecast, num_sce):\n",
        "    '''\n",
        "    This solver more flexible, only assume y is affine in total imbalance, and do not\n",
        "    enforce the coefficients summing up to 1. both alpha and beta are determined after observing \n",
        "    uncertainty realizations.\n",
        "    '''\n",
        "\n",
        "    M = num_sce\n",
        "\n",
        "    # c = da_cost_Coeff\n",
        "    # q = linear_cost_Coeff\n",
        "    B = -Yrr\n",
        "    F = Arr\n",
        "    rho_lb = 10.\n",
        "    rho_ub = 10.\n",
        "    gamma_lb = 10.\n",
        "    gamma_ub = 10.\n",
        "    ones = np.ones((N,1))\n",
        "\n",
        "    Brr = -Yrr[1:,:]\n",
        "    Brr_inv = np.linalg.inv(Brr)\n",
        "    I = np.eye(N)\n",
        "    R = I[1:,:]\n",
        "    \n",
        "    # first-stage decision variables\n",
        "    x = cp.Variable((N, 1))\n",
        "    r_up = cp.Variable((N, 1))\n",
        "    r_down = cp.Variable((N, 1))\n",
        "    \n",
        "    # second-stage decision variables\n",
        "    alpha = cp.Variable((N, 1))\n",
        "    beta = cp.Variable((N,1))\n",
        "\n",
        "\n",
        "    constraints_list = []\n",
        "    Q_vals = []\n",
        "\n",
        "    PD = forecast.flatten()\n",
        "    std_vec = PD*sce_std\n",
        "    std_vec = np.where(std_vec<1e-5, 0.1, std_vec)\n",
        "\n",
        "    # generate M uncertainty realizations using the given forecast as mean\n",
        "    # vector and 5% of it as std.\n",
        "    scenarios = np.random.multivariate_normal(PD, np.diag(std_vec), M)\n",
        "    scenarios = np.clip(scenarios, a_min=0., a_max=None).T\n",
        "    assert scenarios.shape[0] == N\n",
        "\n",
        "    for m in range(M):\n",
        "        # for each scenario of noise\n",
        "        omega =  scenarios[:, m:m+1] - forecast\n",
        "        net_d = scenarios[:, m:m+1] - x\n",
        "\n",
        "        y_pred = (ones.T@omega)*alpha + beta\n",
        "        theta_pred = Brr_inv@R@(net_d-y_pred)\n",
        "\n",
        "        constraints_list.append( y_pred == Yrr@theta_pred + net_d )\n",
        "\n",
        "        p_f_lb = rho_lb*cp.square( cp.norm( cp.pos(-Fmax*np.ones((num_lines, 1)) - F@theta_pred) ) )\n",
        "        p_f_ub = rho_ub*cp.square( cp.norm(  cp.pos(F@theta_pred -Fmax*np.ones((num_lines, 1))) ) )\n",
        "\n",
        "        p_theta_lb  = rho_lb*cp.square( cp.norm(  cp.pos(-np.pi*np.ones((N-1, 1)) - theta_pred) ) )\n",
        "        p_theta_ub  = rho_ub*cp.square( cp.norm(  cp.pos(theta_pred - np.pi*np.ones((N-1, 1))) ) )\n",
        "\n",
        "        p_y_ub  = gamma_lb*cp.square( cp.norm( cp.pos(x+y_pred-Pmax*np.ones((N, 1))) ))\n",
        "        p_y_lb  = gamma_ub*cp.square( cp.norm( cp.pos(Pmin*np.ones((N, 1))-(x+y_pred) ) ))\n",
        "\n",
        "        recourse_cost = cp.abs(y_pred).T@q +\\\n",
        "                cp.pos(y_pred-r_up).T@q*RecourseReserveCostFactor +\\\n",
        "                cp.pos(y_pred+r_down).T@q*RecourseReserveCostFactor\n",
        "\n",
        "        Q_val = recourse_cost + p_f_lb + p_f_ub + p_theta_lb + p_theta_ub\n",
        "        Q_val += p_y_ub + p_y_lb\n",
        "\n",
        "        Q_vals.append(Q_val)\n",
        "\n",
        "    constraints_list.append( ones.T@x== ones.T@forecast)\n",
        "    constraints_list.append( x+r_up <= Pmax*np.ones((N, 1)))\n",
        "    constraints_list.append( x-r_down >= Pmin*np.ones((N, 1)))\n",
        "    constraints_list.append( x>=Pmin)\n",
        "    constraints_list.append( x<=Pmax)\n",
        "    constraints_list.append( r_up>=0)\n",
        "    constraints_list.append( r_down>=0)\n",
        "\n",
        "    Q_pred = cp.sum(Q_vals)/M\n",
        "\n",
        "    da_cost = c.T@x + DayAheadReserveCostFactor*c.T@(r_up+r_down)\n",
        "\n",
        "    prob = cp.Problem(cp.Minimize( da_cost + Q_pred ), constraints_list)\n",
        "\n",
        "    prob.solve(verbose = False, solver = cp.ECOS) ## Works!  \n",
        "\n",
        "    solutions = np.concatenate([x.value.T, r_up.value.T, r_down.value.T], axis=-1)\n",
        "\n",
        "\n",
        "    return solutions, prob.value, prob.status"
      ],
      "metadata": {
        "id": "sHWu4YTYXEkm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_SAA(forecast, num_sce):\n",
        "    '''\n",
        "    Given a single instance of forecast, solve the SAA version\n",
        "    of the true problem.\n",
        "    This is called cp policy in our work.\n",
        "    '''\n",
        "\n",
        "    M = num_sce\n",
        "    ones = np.ones((N,1))\n",
        "\n",
        "    x = cp.Variable((N, 1))\n",
        "    r_up = cp.Variable((N, 1))\n",
        "    r_down = cp.Variable((N, 1))\n",
        "    theta = cp.Variable((N-1,M))\n",
        "    y = cp.Variable((N, M))\n",
        "\n",
        "    constraints_list = []\n",
        "\n",
        "    PD = forecast.flatten()\n",
        "    std_vec = PD*sce_std\n",
        "    std_vec = np.where(std_vec<1e-5, 0.1, std_vec)\n",
        "\n",
        "    scenarios = np.random.multivariate_normal(PD, np.diag(std_vec), M)\n",
        "    scenarios = np.clip(scenarios, a_min=0., a_max=None).T\n",
        "    assert scenarios.shape[0] == N\n",
        "\n",
        "    for m in range(M):\n",
        "\n",
        "        net_d = scenarios[:, m:m+1] - x\n",
        "\n",
        "        constraints_list.append( y[:,m:m+1] == Yrr@theta[:,m:m+1] + net_d )\n",
        "\n",
        "        constraints_list.append( x+y[:,m:m+1]<=Pmax*np.ones((N, 1)))\n",
        "        constraints_list.append( x+y[:,m:m+1]>=Pmin*np.ones((N, 1)))\n",
        "        # constraints_list.append( ones.T@y[:,m:m+1]<=ones.T@r_up)\n",
        "        # constraints_list.append( ones.T@y[:,m:m+1]>=-ones.T@r_down)\n",
        "            \n",
        "    constraints_list.append( Arr@theta <= Fmax*np.ones((num_lines, M)))\n",
        "    constraints_list.append( Arr@theta >= -Fmax*np.ones((num_lines, M)))\n",
        "\n",
        "    constraints_list.append( theta<=np.pi)\n",
        "    constraints_list.append( theta>=-np.pi)\n",
        "    \n",
        "    constraints_list.append( ones.T@x== ones.T@forecast)\n",
        "    constraints_list.append( x+r_up <= Pmax*np.ones((N, 1)))\n",
        "    constraints_list.append( x-r_down >= Pmin*np.ones((N, 1)))\n",
        "    constraints_list.append( x>=Pmin)\n",
        "    constraints_list.append( x<=Pmax)\n",
        "    constraints_list.append( r_up>=0)\n",
        "    constraints_list.append( r_down>=0)\n",
        "\n",
        "    Q_vals = []\n",
        "    for m in range(M):\n",
        "\n",
        "        # total_cost += cp.quad_form(y[:,m:m+1], quad_cost_Coeff) + y[:,m:m+1].T@linear_cost_Coeff\n",
        "        recourse_cost = cp.abs(y[:,m:m+1]).T@q +\\\n",
        "                        cp.pos(y[:,m:m+1]-r_up).T@q*RecourseReserveCostFactor +\\\n",
        "                        cp.pos(y[:,m:m+1]+r_down).T@q*RecourseReserveCostFactor\n",
        "        Q_vals.append(recourse_cost)\n",
        "\n",
        "    Q_pred = cp.sum(Q_vals)/M\n",
        "    da_cost = c.T@x + DayAheadReserveCostFactor*c.T@(r_up+r_down)\n",
        "    prob = cp.Problem(cp.Minimize( da_cost + Q_pred ), constraints_list)\n",
        "   \n",
        "    # prob.solve(verbose = False, solver = cp.ECOS) ## Works! \n",
        "    # prob.solve(verbose = False, solver = cp.MOSEK) ## Works!\n",
        "    prob.solve(verbose = False, solver = cp.SCS) ## Works!\n",
        "    # if prob.status in [\"infeasible\", \"unbounded\"]:\n",
        "    #     print(\"Problem is \" + str(prob.status))\n",
        "\n",
        "    solutions = np.concatenate([x.value.T, r_up.value.T, r_down.value.T], axis=-1)\n",
        "\n",
        "\n",
        "    return solutions, prob.value, prob.status\n",
        "\n",
        "\n",
        "def solver_outer_loop(forecasts, num_sce, solver_name):\n",
        "    '''\n",
        "    Given a batch of instances and solve rld problem for each instance.\n",
        "    We only care about x for now.\n",
        "    Can return computation time for each instance at the same time (in minutes)\n",
        "    '''\n",
        "\n",
        "    num_points = forecasts.shape[0]\n",
        "\n",
        "    x_vals = []\n",
        "    total_cost_vals = []\n",
        "    times = []\n",
        "\n",
        "\n",
        "    for it in range(num_points):\n",
        "\n",
        "        forecast = forecasts[it,:].reshape(-1,1)\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if solver_name == 'saa':\n",
        "            x_value, prob_value, prob_status = solve_SAA(forecast, num_sce)\n",
        "\n",
        "        elif solver_name == 'ap':\n",
        "            x_value, prob_value, prob_status = solve_AP(forecast, num_sce)\n",
        "\n",
        "        elif solver_name == 'm_gap':\n",
        "            x_value, prob_value, prob_status = solve_modified_GAP(forecast, num_sce)\n",
        "\n",
        "        elif solver_name == 'gap':\n",
        "            x_value, prob_value, prob_status = solve_GAP(forecast, num_sce)\n",
        "\n",
        "        # elif solver_name == 'pwa':\n",
        "        #     x_value, prob_value, prob_status = solve_PWA(forecast, num_sce)\n",
        "\n",
        "        else:\n",
        "            print('No such solver exists!')\n",
        "\n",
        "        if prob_status in [\"infeasible\", \"unbounded\"]:\n",
        "            print(\"Problem is \" + str(prob_status))\n",
        "            x_value = np.inf*np.ones((N, 1))\n",
        "            prob_value = np.inf\n",
        "\n",
        "        end_time = time.time()\n",
        "        times.append((end_time-start_time)/60)\n",
        "\n",
        "        x_vals.append(x_value.flatten())\n",
        "        total_cost_vals.append(prob_value)\n",
        "\n",
        "        # print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
        "        \n",
        "    x_vals = np.array(x_vals)\n",
        "    total_cost_vals = np.array(total_cost_vals).reshape(-1,1)\n",
        "    times = np.array(times)\n",
        "\n",
        "    return x_vals, total_cost_vals, times\n"
      ],
      "metadata": {
        "id": "jKB5S8_UnUyV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate policy"
      ],
      "metadata": {
        "id": "57E9Gt-W28sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_Q(forecast, x, num_sce):\n",
        "    '''\n",
        "    Given a single instance and the initial dispatch x, and evaluate the quality\n",
        "    of x.\n",
        "    This function can be applied to the decision obtained from any policy.\n",
        "    '''\n",
        "\n",
        "    M = num_sce \n",
        "    ones = np.ones((N,1))\n",
        "\n",
        "    p0 = x[:N,:]\n",
        "    r_up = x[N:N+N,:]\n",
        "    r_down = x[N+N:,:]\n",
        "\n",
        "    theta = cp.Variable((N-1,M))\n",
        "    y = cp.Variable((N, M))\n",
        "\n",
        "\n",
        "    net_d_vals = np.zeros((N, M))\n",
        "\n",
        "    constraints_list = []\n",
        "\n",
        "    PD = forecast.flatten()\n",
        "    std_vec = PD*sce_std\n",
        "    std_vec = np.where(std_vec<1e-5, 0.1, std_vec)\n",
        "\n",
        "    scenarios = np.random.multivariate_normal(PD, np.diag(std_vec), M)\n",
        "    scenarios = np.clip(scenarios, a_min=0., a_max=None).T\n",
        "    assert scenarios.shape[0] == N\n",
        "\n",
        "    for m in range(M):\n",
        "        net_d = scenarios[:, m:m+1] - p0\n",
        "        \n",
        "        # net_d_vals[:,m:m+1] = net_d\n",
        "\n",
        "        constraints_list.append( y[:,m:m+1] == Yrr@theta[:,m:m+1] + net_d )\n",
        "        constraints_list.append( p0 + y[:,m:m+1]<=Pmax*np.ones((N, 1)))\n",
        "        constraints_list.append( p0 + y[:,m:m+1]>=Pmin*np.ones((N, 1)))\n",
        "        # constraints_list.append( ones.T@y[:,m:m+1]<=ones.T@r_up)\n",
        "        # constraints_list.append( ones.T@y[:,m:m+1]>=-ones.T@r_down)\n",
        "        \n",
        "    constraints_list.append( Arr@theta <= Fmax*np.ones((num_lines, M)))\n",
        "    constraints_list.append( Arr@theta >= -Fmax*np.ones((num_lines, M)))\n",
        "\n",
        "    constraints_list.append( theta<=np.pi)\n",
        "    constraints_list.append( theta>=-np.pi)\n",
        "\n",
        "    Q_vals = []\n",
        "    for m in range(M):\n",
        "        recourse_cost = cp.abs(y[:,m:m+1]).T@q+\\\n",
        "                cp.pos(y[:,m:m+1]-r_up).T@q*RecourseReserveCostFactor +\\\n",
        "                cp.pos(y[:,m:m+1]+r_down).T@q*RecourseReserveCostFactor \n",
        "\n",
        "        Q_vals.append(recourse_cost)\n",
        "\n",
        "    Q_pred = cp.sum(Q_vals)/M\n",
        "\n",
        "    prob = cp.Problem(cp.Minimize( Q_pred ), constraints_list)\n",
        "\n",
        "    prob.solve(verbose = False, solver = cp.SCS) ## Works!   \n",
        "\n",
        "    if prob.status in [\"infeasible\", \"unbounded\"]:\n",
        "            return prob.value, np.inf*np.ones((N,1)), prob.status\n",
        "\n",
        "    return prob.value, np.sum(y.value, axis=1)/M, prob.status\n",
        "\n",
        "\n",
        "def evaluate_outer_loop(forecasts, x_pred, num_sce):\n",
        "    '''\n",
        "    Given a batch of instances and the associated predictions of first stage decision,\n",
        "    and evaluate these initial dispatch decisions for each instance.\n",
        "\n",
        "    '''\n",
        "\n",
        "    num_points = forecasts.shape[0]\n",
        "\n",
        "    Q_pred = []\n",
        "    y_pred = []\n",
        "\n",
        "    for i in range(num_points):\n",
        "        forecast = forecasts[i,:].reshape(-1,1)\n",
        "        init_dispatch = x_pred[i,:].reshape(-1,1)\n",
        "\n",
        "        Q_value, avg_y_value, prob_status = evaluate_Q(forecast, init_dispatch, num_sce)\n",
        "\n",
        "        if prob_status in [\"infeasible\", \"unbounded\"]:\n",
        "            print(\"Problem is \" + str(prob_status))\n",
        "            avg_y_value = np.inf*np.ones((N, 1))\n",
        "            Q_value = np.inf\n",
        "\n",
        "        Q_pred.append(Q_value)\n",
        "        y_pred.append(avg_y_value.flatten())\n",
        "        \n",
        "\n",
        "    Q_pred = np.array(Q_pred).reshape(-1,1)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    p0 = x_pred[:,:N]\n",
        "    r_up = x_pred[:,N:N+N]\n",
        "    r_down = x_pred[:,N+N:]\n",
        "\n",
        "    da_cost = (p0+r_up+r_down)@c\n",
        "    total_cost_pred = (p0+r_up+r_down)@c + Q_pred\n",
        "    \n",
        "\n",
        "    return total_cost_pred, Q_pred, y_pred"
      ],
      "metadata": {
        "id": "Uxvmp52R2-Vq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load.py"
      ],
      "metadata": {
        "id": "tXxVw37GGob7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nominal_PD_data = PD_data.reshape(1,-1)\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "train_dataset = np.load(data_path+'train_set.npy')\n",
        "test_dataset = np.load(data_path+'test_set.npy')\n",
        "pretrain_dataset = np.load(data_path+'pretrain_set.npy')\n",
        "\n",
        "Ntr = train_dataset.shape[0]\n",
        "Ntr2 = pretrain_dataset.shape[0]\n",
        "Ntst = test_dataset.shape[0]\n",
        "\n",
        "\n",
        "print('train set:', train_dataset.shape)\n",
        "print('test set:', test_dataset.shape)\n",
        "print('pretrain set:', pretrain_dataset.shape)"
      ],
      "metadata": {
        "id": "g1PKjAMWLCHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6fe9102-cd59-419c-ee05-b6f05c2e709c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: (50000, 39)\n",
            "test set: (100, 39)\n",
            "pretrain set: (100, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# benchmarks(gurobi)"
      ],
      "metadata": {
        "id": "fU1BAiX0LzIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gurobipy>=9.5.1"
      ],
      "metadata": {
        "id": "N0WHS422L3N9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gurobi WLS license file\n",
        "# Your credentials are private and should not be shared or copied to public repositories.\n",
        "# Visit https://license.gurobi.com/manager/doc/overview for more information.\n",
        "WLSACCESSID='cb9b0a86-05f8-4e07-b0c4-6eac1ede9e8c'\n",
        "WLSSECRET='52f11ad6-e6ea-41ea-b78b-3ebf1876527e'\n",
        "LicenseID = 866142\n"
      ],
      "metadata": {
        "id": "NPfsQtYwE-3Q"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "\n",
        "# tested with Python 3.7.0 & Gurobi 9.1.0"
      ],
      "metadata": {
        "id": "VAIFvcwblCQQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment with WLS license\n",
        "e = gp.Env(empty=True)\n",
        "e.setParam('WLSACCESSID', WLSACCESSID)\n",
        "e.setParam('WLSSECRET', WLSSECRET)\n",
        "e.setParam('LICENSEID', LicenseID)\n",
        "e.start()\n",
        "\n",
        "# Create the model within the Gurobi environment\n",
        "# model = gp.Model(env=e)\n",
        "solve_saa = gp.Model(env=e,name='solve_saa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "vFipm3YSFjyj",
        "outputId": "9b88b4d9-6b1d-4143-ca7f-3b5c816303f3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set parameter WLSAccessID\n",
            "Set parameter WLSSecret\n",
            "Set parameter LicenseID\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "GurobiError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-28d69543d8cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WLSSECRET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWLSSECRET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LICENSEID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLicenseID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create the model within the Gurobi environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/gurobipy/env.pxi\u001b[0m in \u001b[0;36mgurobipy.Env.start\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mGurobiError\u001b[0m: License not allowed"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input data\n",
        "Define all the input data for the model."
      ],
      "metadata": {
        "id": "YLmtLnpvt_sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pmax_vec = Pmax*np.ones((N,1))\n",
        "# Pmin_vec = Pmin*np.ones((N,1))\n",
        "# Fmax_vec = Fmax*np.ones((L,1))\n",
        "forecast = pretrain_dataset[:1,:]\n",
        "ones = np.ones((N,1))\n",
        "c_r = DayAheadReserveCostFactor*c\n",
        "\n",
        "M = 10\n",
        "\n",
        "# generate M uncertainty realizations\n",
        "PD = forecast.flatten()\n",
        "std_vec = PD*sce_std\n",
        "std_vec = np.where(std_vec<1e-5, 0.1, std_vec)\n",
        "\n",
        "scenarios = np.random.multivariate_normal(PD, np.diag(std_vec), M)\n",
        "scenarios = np.clip(scenarios, a_min=0., a_max=None).T\n",
        "assert scenarios.shape[0] == N\n"
      ],
      "metadata": {
        "id": "obLFEfrEr3OK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model deployment"
      ],
      "metadata": {
        "id": "I1-nRV792uKB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XF9AZUUW22GV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add variables x, r_up, r_down indexed by {1,2,...,N}\n",
        "# add variables y, theta: y indexed by {1,2,...,N} times {1,2,...,M}\n",
        "# and theta indexed by {1,2,...,N-1} times {1,2,...,M}\n",
        "# where M is the number of uncertainty realizations (named scenarios here)\n",
        "\n",
        "# Define sets and indices\n",
        "GenSet = list(range(N))\n",
        "LineSet = list(range(L))\n",
        "SceSet = list(range(M))\n",
        "\n",
        "# Add variables\n",
        "x = solve_saa.addVars(GenSet, lb=Pmin, ub=Pmax, \n",
        "                      name=\"p0\")\n",
        "# Add non-negative variables r_up, r_down\n",
        "r_up = solve_saa.addVars(GenSet, name=\"up reserve\")\n",
        "r_down = solve_saa.addVars(GenSet,  name=\"down reserve\")\n",
        "# Add matrix variables y and theta\n",
        "y = solve_saa.addVars(GenSet, SceSet, name=\"recourse\")\n",
        "theta = solve_saa.addVars(LineSet, SceSet, name=\"angles\")\n",
        "\n",
        "# Add constraints\n",
        "\n",
        "solve_saa.addConstr(x.sum('*') == np.sum(forecast), 'initial balance')\n",
        "solve_saa.addConstrs( (x[i] + r_up[i] <= Pmax for i in GenSet), 'up reserve')\n",
        "solve_saa.addConstrs( (x[i] - r_down[i] >= Pmin for i in GenSet), 'down reserve')\n",
        "\n",
        "\n",
        "# Set objective function\n",
        "solve_saa.setObjective(gp.quicksum(c[i,0]*x[i] + c_r[i,0]*(r_up[i]+r_down[i]) for i in GenSet))\n",
        "\n",
        "# Verify model formulation\n",
        "solve_saa.write('solve_saa.lp')\n",
        "\n",
        "# Run optimization engine\n",
        "solve_saa.optimize()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "oKBCFNYf28Cx",
        "outputId": "b1c20e1b-2052-46d0-8dd8-7d4b5ffaa6c1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: variable name \"up reserve[0]\" has a space\n",
            "Warning: constraint name \"initial balance\" has a space\n",
            "Warning: to let Gurobi read it back, use rlp format\n",
            "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
            "Thread count: 1 physical cores, 2 logical processors, using up to 2 threads\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "GurobiError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-a53b1328b69b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Run optimization engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0msolve_saa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/gurobipy/model.pxi\u001b[0m in \u001b[0;36mgurobipy.Model.optimize\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mGurobiError\u001b[0m: Model too large for size-limited license; visit https://www.gurobi.com/free-trial for a full license"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wauekHoG654n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}